{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importaciones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 585,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Módulo para crear un modelo predictivo de precios de Airbnb en la Comunidad de Madrid.\"\"\"\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, KFold, GridSearchCV\n",
    "from sklearn.ensemble import RandomForestRegressor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Descargar los datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_location = \"https://data.insideairbnb.com/spain/comunidad-de-madrid/madrid/2024-03-22/data/listings.csv.gz\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2024-06-01 19:46:38--  https://data.insideairbnb.com/spain/comunidad-de-madrid/madrid/2024-03-22/data/listings.csv.gz\n",
      "Resolving data.insideairbnb.com (data.insideairbnb.com)... 18.154.48.59, 18.154.48.87, 18.154.48.41, ...\n",
      "Connecting to data.insideairbnb.com (data.insideairbnb.com)|18.154.48.59|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 13297683 (13M) [application/x-gzip]\n",
      "Saving to: ‘listings.csv.gz’\n",
      "\n",
      "listings.csv.gz     100%[===================>]  12.68M  17.1MB/s    in 0.7s    \n",
      "\n",
      "2024-06-01 19:46:39 (17.1 MB/s) - ‘listings.csv.gz’ saved [13297683/13297683]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!wget https://data.insideairbnb.com/spain/comunidad-de-madrid/madrid/2024-03-22/data/listings.csv.gz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 558,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reasoning behind which columns are removed, and which require text processing\n",
    "columns = [\n",
    "    'id',                     # Remove - Identifier\n",
    "    'listing_url',            # Remove - URL with ID at end\n",
    "    'scrape_id',              # Remove - details of scrape\n",
    "    'last_scraped',           # Remove - detail of scrape\n",
    "    'source',                 # Remove - detail of scrape\n",
    "    'name',                   # Do text processing\n",
    "    'description',            # Do text processing\n",
    "    'neighborhood_overview',  # Do text processing\n",
    "    'picture_url',            # Remove - URl\n",
    "    'host_id',                # Could learn relation between host and price\n",
    "    'host_url',               # Remove - redundant with host_id\n",
    "    'host_name',              # Do text processing\n",
    "    'host_since',             # Convert to number of months or years \n",
    "    'host_location',          # Do text processing\n",
    "    'host_about',             # Do text processing\n",
    "    'host_response_time', 'host_response_rate',\n",
    "    'host_acceptance_rate', 'host_is_superhost',\n",
    "    'host_thumbnail_url',     # Remove\n",
    "    'host_picture_url',       # Remove\n",
    "    'host_neighbourhood',     # Do text processing\n",
    "    'host_listings_count', 'host_total_listings_count',\n",
    "    'host_verifications',     #\n",
    "    'host_has_profile_pic', 'host_identity_verified',\n",
    "    'neighbourhood',          #  Remove - redundant\n",
    "    'neighbourhood_cleansed', #  Do text processing\n",
    "    'neighbourhood_group_cleansed',\n",
    "    'latitude', 'longitude',  # Consider removing, redundant with neighbourhood_cleansed\n",
    "    'property_type',          #  Do text processing\n",
    "    'room_type', 'accommodates', 'bathrooms',\n",
    "    'bathrooms_text',         # Remove - largely redundant\n",
    "    'bedrooms', 'beds', 'amenities',\n",
    "    'price',                  # Dependent variable\n",
    "    'minimum_nights', 'maximum_nights', 'minimum_minimum_nights',\n",
    "    'maximum_minimum_nights', 'minimum_maximum_nights',\n",
    "    'maximum_maximum_nights', 'minimum_nights_avg_ntm',\n",
    "    'maximum_nights_avg_ntm',\n",
    "    'calendar_updated',       # Remove - 0 not null\n",
    "    'has_availability',\n",
    "    'availability_30', 'availability_60', 'availability_90',\n",
    "    'availability_365',\n",
    "    'calendar_last_scraped',  # Remove - same across all rows\n",
    "    'number_of_reviews',\n",
    "    'number_of_reviews_ltm', 'number_of_reviews_l30d',\n",
    "    'first_review', 'last_review',  # Convert to days ago\n",
    "    'review_scores_rating', 'review_scores_accuracy',\n",
    "    'review_scores_cleanliness', 'review_scores_checkin',\n",
    "    'review_scores_communication', 'review_scores_location',\n",
    "    'review_scores_value',\n",
    "    'license',                # Remove \n",
    "    'instant_bookable',\n",
    "    'calculated_host_listings_count',\n",
    "    'calculated_host_listings_count_entire_homes',\n",
    "    'calculated_host_listings_count_private_rooms',\n",
    "    'calculated_host_listings_count_shared_rooms', 'reviews_per_month'   \n",
    "]\n",
    "\n",
    "data_types = {\n",
    "    'price': pd.StringDtype(),\n",
    "    'host_response_time': pd.StringDtype(),\n",
    "    'host_response_rate': pd.StringDtype(),\n",
    "    'host_acceptance_rate': pd.StringDtype(),\n",
    "    'host_is_superhost': pd.StringDtype(),\n",
    "    'host_has_profile_pic': pd.StringDtype(),\n",
    "    'host_identity_verified': pd.StringDtype(),\n",
    "    'room_type': pd.StringDtype(),\n",
    "    'has_availability': pd.StringDtype(),\n",
    "    'instant_bookable': pd.StringDtype(),\n",
    "    'name': pd.StringDtype(),\n",
    "    'description': pd.StringDtype(),\n",
    "    'neighborhood_overview': pd.StringDtype(),\n",
    "    'host_name': pd.StringDtype(),\n",
    "    'host_location': pd.StringDtype(),\n",
    "    'host_about': pd.StringDtype(),\n",
    "    'host_neighbourhood': pd.StringDtype(),\n",
    "    'neighbourhood_cleansed': pd.StringDtype(),\n",
    "    'neighbourhood_group_cleansed': pd.StringDtype(),\n",
    "    'property_type': pd.StringDtype(),\n",
    "    'host_verifications': pd.StringDtype(),\n",
    "    'amenities': pd.StringDtype(),\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cargar los datos y crear subconjuntos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 559,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20688, 75)"
      ]
     },
     "execution_count": 559,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parse_dates = ['host_since','first_review','last_review']\n",
    "\n",
    "data = pd.read_csv('listings.csv.gz', parse_dates=parse_dates, dtype=data_types)\n",
    "\n",
    "# Select only data where there exists a price\n",
    "data = data[data['price'].notnull()]\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 560,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 560,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['price'].isnull().values.any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 561,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols_of_interest = [\n",
    "    'price', 'host_id', 'host_since', 'host_response_time', 'host_response_rate',\n",
    "    'host_acceptance_rate', 'host_is_superhost', 'host_listings_count',\n",
    "    'host_total_listings_count', 'host_verifications', 'host_has_profile_pic',\n",
    "    'host_identity_verified', 'latitude', 'longitude', 'room_type', 'accommodates',\n",
    "    'bathrooms', 'bedrooms', 'beds', 'minimum_nights', 'maximum_nights',\n",
    "    'minimum_minimum_nights', 'maximum_minimum_nights', 'minimum_maximum_nights',\n",
    "    'maximum_maximum_nights', 'minimum_nights_avg_ntm', 'maximum_nights_avg_ntm',\n",
    "    'has_availability', 'availability_30', 'availability_60', 'availability_90',\n",
    "    'availability_365', 'number_of_reviews', 'number_of_reviews_ltm', 'number_of_reviews_l30d',\n",
    "    'first_review', 'last_review', 'review_scores_rating', 'review_scores_accuracy',\n",
    "    'review_scores_cleanliness', 'review_scores_checkin', 'review_scores_communication',\n",
    "    'review_scores_location', 'review_scores_value', 'instant_bookable',\n",
    "    'calculated_host_listings_count', 'calculated_host_listings_count_entire_homes',\n",
    "    'calculated_host_listings_count_private_rooms', 'calculated_host_listings_count_shared_rooms',\n",
    "    'reviews_per_month'\n",
    "                   ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 562,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Columns to that require text processing\n",
    "cols_text = [\n",
    "    'name', 'description', 'neighborhood_overview', 'host_name', \n",
    "    'host_location', 'host_about', 'host_neighbourhood', 'neighbourhood_cleansed',\n",
    "    'neighbourhood_group_cleansed', 'property_type', 'amenities'\n",
    "            ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 576,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((20688, 50), (20688, 11))"
      ]
     },
     "execution_count": 576,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create data subsets\n",
    "data_numerical = data[cols_of_interest]\n",
    "data_text = data[cols_text]\n",
    "\n",
    "data_numerical.shape, data_text.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ingeniería de Características"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cleaning numerical columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 577,
   "metadata": {},
   "outputs": [],
   "source": [
    "# COLS FOR LATER\n",
    "# 'amenities'            # list of strings lalala\n",
    "pd.options.mode.copy_on_write = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 578,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0         31.0\n",
       "1         92.0\n",
       "2        180.0\n",
       "4         65.0\n",
       "5         32.0\n",
       "         ...  \n",
       "26019    108.0\n",
       "26020     40.0\n",
       "26021     28.0\n",
       "26022     28.0\n",
       "26023    100.0\n",
       "Name: price, Length: 20688, dtype: float64"
      ]
     },
     "execution_count": 578,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_numerical['price'] =  data_numerical['price'].replace({\"[\\$,)]\":\"\",\",\":\"\"}, regex=True).apply(pd.to_numeric)\n",
    "y = data_numerical['price']\n",
    "data_numerical = data_numerical.drop(['price'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 566,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate years hosting\n",
    "data_numerical['host_since_year'] = data_numerical['host_since'].apply(lambda x: x.year)\n",
    "data_numerical['host_years'] = data_numerical['host_since_year'].apply(lambda x: 2024.0 - x)\n",
    "data_numerical = data_numerical.drop(['host_since', 'host_since_year'], axis=1)\n",
    "\n",
    "# Calculate years since first review\n",
    "data_numerical['first_review_year'] = data_numerical['first_review'].apply(lambda x: x.year)\n",
    "data_numerical['first_review_age'] = data_numerical['first_review_year'].apply(lambda x: 2024.0 - x)\n",
    "data_numerical = data_numerical.drop(['first_review', 'first_review_year'], axis=1)\n",
    "\n",
    "# Calculate years since last review\n",
    "data_numerical['last_review_year'] = data_numerical['last_review'].apply(lambda x: x.year)\n",
    "data_numerical['last_review_age'] = data_numerical['last_review_year'].apply(lambda x: 2024.0 - x)\n",
    "data_numerical = data_numerical.drop(['last_review', 'last_review_year'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 567,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change t f columns to 1 and 0\n",
    "columns_t_f = ['host_is_superhost','host_has_profile_pic', 'host_identity_verified','has_availability','instant_bookable']\n",
    "t_f = {'t':'1', 'f':'0'}\n",
    "\n",
    "for col in columns_t_f:\n",
    "    data_numerical[col] = data_numerical[col].replace(t_f)\n",
    "\n",
    "data_numerical[columns_t_f] = data_numerical[columns_t_f].apply(pd.to_numeric)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 568,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Strip % and convert int\n",
    "columns_percent = ['host_response_rate','host_acceptance_rate']\n",
    "\n",
    "for col in columns_percent:\n",
    "    data_numerical[col] = data_numerical[col].str.replace('%', '').apply(pd.to_numeric)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 569,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert to category strings to numerical codes\n",
    "columns_categorical = ['host_response_time', 'room_type']\n",
    "\n",
    "label_encoder = LabelEncoder()\n",
    "data_numerical[columns_categorical] = data_numerical[columns_categorical].apply(lambda series: pd.Series(\n",
    "    LabelEncoder().fit_transform(series[series.notnull()]),\n",
    "))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 570,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean string\n",
    "data_numerical['host_verifications'] = data_numerical['host_verifications'].str.replace(r\"[\\'\\[\\]]\", \"\", regex=True)\n",
    "data_numerical['host_verifications'] = data_numerical['host_verifications'].str.replace(\" \", \"\")\n",
    "\n",
    "verification_cols = ['email_verified', 'phone_verified','work_email_verified']\n",
    "\n",
    "# Expand columns\n",
    "data_numerical[verification_cols] = data_numerical['host_verifications'].str.split(',', expand=True)\n",
    "\n",
    "# Convert to 1 and 0\n",
    "data_numerical[verification_cols] = data_numerical[verification_cols].notnull().astype(float)\n",
    "\n",
    "# Drop original column\n",
    "data_numerical = data_numerical.drop(['host_verifications'], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Final data transformations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 571,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Handle Nulls usint interpolate\n",
    "for col in data_numerical.columns:\n",
    "    if data_numerical.isnull().values.any():\n",
    "        data_numerical[col] = data_numerical[col].astype(float)\n",
    "        data_numerical[col] = data_numerical[col].interpolate(method='linear')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 572,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize data using min-max normalization\n",
    "normalized_numerical_data=(data_numerical-data_numerical.min())/(data_numerical.max()-data_numerical.min())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train test splits\n",
    "\n",
    "https://towardsdatascience.com/hyperparameter-tuning-the-random-forest-in-python-using-scikit-learn-28d2aa77dd74"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 579,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    normalized_numerical_data, y, test_size=0.33, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 582,
   "metadata": {},
   "outputs": [],
   "source": [
    "#np.random.seed(42)\n",
    "#from sklearn import linear_model\n",
    "#br = linear_model.BayesianRidge()\n",
    "def evaluate(model, test_features, test_labels):\n",
    "    predictions = model.predict(test_features)\n",
    "    errors = abs(predictions - test_labels)\n",
    "    mape = 100 * np.mean(errors / test_labels)\n",
    "    accuracy = 100 - mape\n",
    "    print('Model Performance')\n",
    "    print('Average Error: {:0.4f} degrees.'.format(np.mean(errors)))\n",
    "    print('Accuracy: {:0.2f}%.'.format(accuracy))\n",
    "    \n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Baseline\n",
    "base_model = RandomForestRegressor(random_state=42)\n",
    "base_model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 588,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['base_model.pkl']"
      ]
     },
     "execution_count": 588,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import joblib\n",
    "joblib.dump(base_model, 'base_model.pkl', compress=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_accuracy = evaluate(base_model, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 587,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "KeyboardInterrupt\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Instantiate model\n",
    "model = RandomForestRegressor(random_state=42)\n",
    "\n",
    "# Dictionary of hyperparameters\n",
    "parameters = {\n",
    "    'n_estimators':[1, 2, 4, 8, 16, 32, 64, 100, 200],\n",
    "    'max_features':['sqrt', 'log2', None],\n",
    "    'random_state':[42],\n",
    "    'min_samples_leaf': [1, 2, 4],\n",
    "    'min_samples_split': [2, 5, 10],\n",
    "    'max_depth': [10, 20, 30, 40, 50, 60, 70, 80, 90, 100, None],\n",
    "            }\n",
    "\n",
    "# Hyperparameter tuning, automatically does 5-fold cv\n",
    "cv = GridSearchCV(model, parameters, n_jobs=-1)\n",
    "cv.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "joblib.dump(cv, 'cv.pkl', compress=True)\n",
    "joblib.dump(cv.best_estimator_, 'cv_best_model.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_best_model = joblib.load('cv_best_model.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_best_model = cv.best_estimator_\n",
    "cv_accuracy = evaluate(cv_best_model, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create k-fold object\n",
    "k_folds = KFold(n_splits=5)\n",
    "\n",
    "# Get cross validation scores\n",
    "scores = cross_val_score(rf, X_train, y_train, cv=k_folds)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
